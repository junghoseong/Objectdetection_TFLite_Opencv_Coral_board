{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.lite as lite\n",
    "from tensorflow.lite.python import lite_constants\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting a GraphDef from file.\n",
    "def from_frozen_graph(graph_def_file):\n",
    "    input_arrays = [\"normalized_input_image_tensor\"]\n",
    "    output_arrays = [\"TFLite_Detection_PostProcess\",\"TFLite_Detection_PostProcess:1\",\"TFLite_Detection_PostProcess:2\",\"TFLite_Detection_PostProcess:3\"]\n",
    "    input_shapes = {\"normalized_input_image_tensor\" : [1, 300, 300, 3]}\n",
    "\n",
    "    converter = lite.TFLiteConverter.from_frozen_graph(\n",
    "        graph_def_file, input_arrays, output_arrays, input_shapes)\n",
    "    return converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting a SavedModel.\n",
    "def from_saved_model(saved_model_dir):\n",
    "    converter = lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "    return converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(converter, out_name, is_quant):\n",
    "    converter.inference_type = lite_constants.QUANTIZED_UINT8 if is_quant else lite_constants.FLOAT\n",
    "    converter.output_format = lite_constants.TFLITE\n",
    "    converter.allow_custom_ops = True\n",
    "    converter.quantized_input_stats = {\"normalized_input_image_tensor\": (128., 1.)} if is_quant else None\n",
    "\n",
    "    print(\"Converting...\")\n",
    "    tflite_model = converter.convert()\n",
    "    open(out_name, \"wb\").write(tflite_model)\n",
    "    print(\"tflite file: {}\".format(out_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb\ttflite_graph\t tflite_graph.pbtxt\n",
      "detect.tflite\ttflite_graph.pb\n",
      "Converting...\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "See console for info.\n2020-12-09 12:51:08.283820: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TFLite_Detection_PostProcess\n2020-12-09 12:51:08.329593: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 878 operators, 1282 arrays (0 quantized)\n2020-12-09 12:51:08.363450: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 878 operators, 1282 arrays (0 quantized)\n2020-12-09 12:51:08.462624: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 100 operators, 262 arrays (1 quantized)\n2020-12-09 12:51:08.467161: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 100 operators, 262 arrays (1 quantized)\n2020-12-09 12:51:08.468248: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 100 operators, 262 arrays (1 quantized)\n2020-12-09 12:51:08.469434: F tensorflow/lite/toco/tooling_util.cc:1728] Array FeatureExtractor/MobilenetV2/Conv/Relu6, which is an input to the DepthwiseConv operator producing the output array FeatureExtractor/MobilenetV2/expanded_conv/depthwise/Relu6, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\nFatal Python error: Aborted\n\nCurrent thread 0x00007f61b002a740 (most recent call first):\n  File \"/home/junghoseong/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52 in execute\n  File \"/home/junghoseong/anaconda3/envs/tf1/lib/python3.7/site-packages/absl/app.py\", line 251 in _run_main\n  File \"/home/junghoseong/anaconda3/envs/tf1/lib/python3.7/site-packages/absl/app.py\", line 300 in run\n  File \"/home/junghoseong/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\n  File \"/home/junghoseong/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89 in main\n  File \"/home/junghoseong/anaconda3/envs/tf1/bin/toco_from_protos\", line 8 in <module>\nAborted (core dumped)\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3705ed165052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mis_quant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mout_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"detect.tflite\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_quant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-bd5cf5e6724f>\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(converter, out_name, is_quant)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Converting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tflite file: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m           \u001b[0minput_arrays_with_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_arrays_with_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m           \u001b[0moutput_arrays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_arrays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m           **converter_kwargs)\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_calibration_quantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_graph_def\u001b[0;34m(input_data, input_arrays_with_shape, output_arrays, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m       \u001b[0mtoco_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[1;32m    413\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    198\u001b[0m       \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"See console for info.\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;31m# Must manually cleanup files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConverterError\u001b[0m: See console for info.\n2020-12-09 12:51:08.283820: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TFLite_Detection_PostProcess\n2020-12-09 12:51:08.329593: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 878 operators, 1282 arrays (0 quantized)\n2020-12-09 12:51:08.363450: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 878 operators, 1282 arrays (0 quantized)\n2020-12-09 12:51:08.462624: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 100 operators, 262 arrays (1 quantized)\n2020-12-09 12:51:08.467161: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 100 operators, 262 arrays (1 quantized)\n2020-12-09 12:51:08.468248: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 100 operators, 262 arrays (1 quantized)\n2020-12-09 12:51:08.469434: F tensorflow/lite/toco/tooling_util.cc:1728] Array FeatureExtractor/MobilenetV2/Conv/Relu6, which is an input to the DepthwiseConv operator producing the output array FeatureExtractor/MobilenetV2/expanded_conv/depthwise/Relu6, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\nFatal Python error: Aborted\n\nCurrent thread 0x00007f61b002a740 (most recent call first):\n  File \"/home/junghoseong/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52 in execute\n  File \"/home/junghoseong/anaconda3/envs/tf1/lib/python3.7/site-packages/absl/app.py\", line 251 in _run_main\n  File \"/home/junghoseong/anaconda3/envs/tf1/lib/python3.7/site-packages/absl/app.py\", line 300 in run\n  File \"/home/junghoseong/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\n  File \"/home/junghoseong/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89 in main\n  File \"/home/junghoseong/anaconda3/envs/tf1/bin/toco_from_protos\", line 8 in <module>\nAborted (core dumped)\n\n\n"
     ]
    }
   ],
   "source": [
    "\"\"\"path = sys.argv[1]\n",
    "print(path)\n",
    "is_quant = \"quant\" in path.lower()\n",
    "print(\"is_quant: {}\".format(is_quant))\n",
    "\n",
    "if path.endswith(\".pb\"):\n",
    "    out_name = path[:-3] + \".tflite\"\n",
    "    converter = from_frozen_graph(path)\n",
    "else:\n",
    "    out_name = path + \".tflite\"\n",
    "    converter = from_saved_model(path)\n",
    "\"\"\"\n",
    "!ls\n",
    "converter = from_frozen_graph(\"./tflite_graph.pb\")\n",
    "is_quant = True\n",
    "out_name = \"detect.tflite\"\n",
    "convert(converter, out_name, is_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
